{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from scipy.fftpack import fft    # Fast Fourier Transform\n",
    "from scipy import stats          # Kernel Density Estimation\n",
    "import pandas as pd              # datafrme\n",
    "import numpy as np               # array\n",
    "from mpl_toolkits.mplot3d import Axes3D # 3D Visualization\n",
    "import matplotlib.pyplot as plt  # Visualization\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "import sys\n",
    "import collections\n",
    "import itertools\n",
    "from scipy.stats import mode\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "      <th>t6</th>\n",
       "      <th>t7</th>\n",
       "      <th>t8</th>\n",
       "      <th>t9</th>\n",
       "      <th>t10</th>\n",
       "      <th>...</th>\n",
       "      <th>t493</th>\n",
       "      <th>t494</th>\n",
       "      <th>t495</th>\n",
       "      <th>t496</th>\n",
       "      <th>t497</th>\n",
       "      <th>t498</th>\n",
       "      <th>t499</th>\n",
       "      <th>t500</th>\n",
       "      <th>t501</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029004</td>\n",
       "      <td>0.009668</td>\n",
       "      <td>0.012891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.022559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009668</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>0.012891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029004</td>\n",
       "      <td>0.025781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.012891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016113</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022559</td>\n",
       "      <td>0.012891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 502 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         t1        t2        t3        t4        t5        t6        t7  \\\n",
       "0  0.019336  0.000000  0.000000  0.000000  0.003223  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.012891  0.000000  0.016113  0.000000  0.006445   \n",
       "2  0.000000  0.009668  0.000000  0.000000  0.006445  0.012891  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.016113  0.006445  0.003223  0.000000   \n",
       "4  0.016113  0.000000  0.000000  0.000000  0.012891  0.000000  0.000000   \n",
       "\n",
       "         t8        t9       t10 ...      t493      t494      t495      t496  \\\n",
       "0  0.000000  0.000000  0.000000 ...  0.029004  0.009668  0.012891  0.000000   \n",
       "1  0.000000  0.003223  0.022559 ...  0.000000  0.000000  0.000000  0.009668   \n",
       "2  0.000000  0.029004  0.025781 ...  0.006445  0.003223  0.012891  0.000000   \n",
       "3  0.022559  0.012891  0.000000 ...  0.000000  0.003223  0.000000  0.000000   \n",
       "4  0.003223  0.003223  0.000000 ...  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "   t497  t498      t499      t500  t501  y  \n",
       "0   0.0   0.0  0.003223  0.003223   0.0  0  \n",
       "1   0.0   0.0  0.000000  0.009668   0.0  0  \n",
       "2   0.0   0.0  0.000000  0.003223   0.0  0  \n",
       "3   0.0   0.0  0.000000  0.000000   0.0  0  \n",
       "4   0.0   0.0  0.000000  0.003223   0.0  0  \n",
       "\n",
       "[5 rows x 502 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('final_data.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal_data = raw_data.loc[raw_data['y'] == 0]\n",
    "#abnormal_data = raw_data.loc[raw_data['y'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 통계치 6개 구해서 RF 돌려보기 or empirical mode decomposition 구해서 RF 돌려보기\n",
    "# knn, dtw 각각 돌려보기 (1-nn + dtw is best?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val, x_test, y_train_val, y_test = train_test_split(raw_data.iloc[:,0:501], raw_data['y'],\n",
    "                                                            test_size = 0.3, stratify = raw_data['y'], random_state = 7)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val.iloc[:,0:501],\n",
    "                                                  y_train_val, test_size = 0.3, stratify = y_train_val, random_state = 667)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "#seed = 7\n",
    "#test_size = 0.3\n",
    "#x_train, x_test, y_train, y_test = train_test_split(raw_data.iloc[:,0:501], raw_data.iloc[:,501], test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, x_train_val.shape[0]):\n",
    "    x_train_val.iloc[i,:] = (x_train_val.iloc[i,:] - min(x_train_val.iloc[i,:])) / (max(x_train_val.iloc[i,:]) - min(x_train_val.iloc[i,:]))\n",
    "    \n",
    "for i in range(0, x_test.shape[0]):\n",
    "    x_test.iloc[i,:] = (x_test.iloc[i,:] - min(x_test.iloc[i,:])) / (max(x_test.iloc[i,:]) - min(x_test.iloc[i,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from IPython.display import clear_output\n",
    "    have_ipython = True\n",
    "except ImportError:\n",
    "    have_ipython = False\n",
    "    \n",
    "class KnnDtw(object):\n",
    "    \"\"\"K-nearest neighbor classifier using dynamic time warping\n",
    "    as the distance measure between pairs of time series arrays\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    n_neighbors : int, optional (default = 5)\n",
    "        Number of neighbors to use by default for KNN\n",
    "        \n",
    "    max_warping_window : int, optional (default = infinity)\n",
    "        Maximum warping window allowed by the DTW dynamic\n",
    "        programming function\n",
    "            \n",
    "    subsample_step : int, optional (default = 1)\n",
    "        Step size for the timeseries array. By setting subsample_step = 2,\n",
    "        the timeseries length will be reduced by 50% because every second\n",
    "        item is skipped. Implemented by x[:, ::subsample_step]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_neighbors=5, max_warping_window=10000, subsample_step=1):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.max_warping_window = max_warping_window\n",
    "        self.subsample_step = subsample_step\n",
    "    \n",
    "    def fit(self, x, l):\n",
    "        \"\"\"Fit the model using x as training data and l as class labels\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        x : array of shape [n_samples, n_timepoints]\n",
    "            Training data set for input into KNN classifer\n",
    "            \n",
    "        l : array of shape [n_samples]\n",
    "            Training labels for input into KNN classifier\n",
    "        \"\"\"\n",
    "        \n",
    "        self.x = x\n",
    "        self.l = l\n",
    "        \n",
    "    def _dtw_distance(self, ts_a, ts_b, d = lambda x,y: abs(x-y)):\n",
    "        \"\"\"Returns the DTW similarity distance between two 2-D\n",
    "        timeseries numpy arrays.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        ts_a, ts_b : array of shape [n_samples, n_timepoints]\n",
    "            Two arrays containing n_samples of timeseries data\n",
    "            whose DTW distance between each sample of A and B\n",
    "            will be compared\n",
    "        \n",
    "        d : DistanceMetric object (default = abs(x-y))\n",
    "            the distance measure used for A_i - B_j in the\n",
    "            DTW dynamic programming function\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        DTW distance between A and B\n",
    "        \"\"\"\n",
    "\n",
    "        # Create cost matrix via broadcasting with large int\n",
    "        ts_a, ts_b = np.array(ts_a), np.array(ts_b)\n",
    "        M, N = len(ts_a), len(ts_b)\n",
    "        cost = float(\"inf\") * np.ones((M, N))\n",
    "\n",
    "        # Initialize the first row and column\n",
    "        cost[0, 0] = d(ts_a[0], ts_b[0])\n",
    "        for i in range(1, M):\n",
    "            cost[i, 0] = cost[i-1, 0] + d(ts_a[i], ts_b[0])\n",
    "\n",
    "        for j in range(1, N):\n",
    "            cost[0, j] = cost[0, j-1] + d(ts_a[0], ts_b[j])\n",
    "\n",
    "        # Populate rest of cost matrix within window\n",
    "        for i in range(1, M):\n",
    "            for j in range(max(1, i - self.max_warping_window),\n",
    "                            min(N, i + self.max_warping_window)):\n",
    "                choices = cost[i - 1, j - 1], cost[i, j-1], cost[i-1, j]\n",
    "                cost[i, j] = min(choices) + d(ts_a[i], ts_b[j])\n",
    "\n",
    "        # Return DTW distance given window \n",
    "        return cost[-1, -1]\n",
    "    \n",
    "    def _dist_matrix(self, x, y):\n",
    "        \"\"\"Computes the M x N distance matrix between the training\n",
    "        dataset and testing dataset (y) using the DTW distance measure\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        x : array of shape [n_samples, n_timepoints]\n",
    "        \n",
    "        y : array of shape [n_samples, n_timepoints]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Distance matrix between each item of x and y with\n",
    "            shape [training_n_samples, testing_n_samples]\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute the distance matrix        \n",
    "        dm_count = 0\n",
    "        \n",
    "        # Compute condensed distance matrix (upper triangle) of pairwise dtw distances\n",
    "        # when x and y are the same array\n",
    "        if(np.array_equal(x, y)):\n",
    "            x_s = shape(x)\n",
    "            dm = np.zeros((x_s[0] * (x_s[0] - 1)) // 2, dtype=np.double)\n",
    "            \n",
    "            p = ProgressBar(shape(dm)[0])\n",
    "            \n",
    "            for i in range(0, x_s[0] - 1):\n",
    "                for j in range(i + 1, x_s[0]):\n",
    "                    dm[dm_count] = self._dtw_distance(x[i, ::self.subsample_step],\n",
    "                                                      y[j, ::self.subsample_step])\n",
    "                    \n",
    "                    dm_count += 1\n",
    "                    p.animate(dm_count)\n",
    "            \n",
    "            # Convert to squareform\n",
    "            dm = squareform(dm)\n",
    "            return dm\n",
    "        \n",
    "        # Compute full distance matrix of dtw distnces between x and y\n",
    "        else:\n",
    "            x_s = np.shape(x)\n",
    "            y_s = np.shape(y)\n",
    "            dm = np.zeros((x_s[0], y_s[0])) \n",
    "            dm_size = x_s[0]*y_s[0]\n",
    "            \n",
    "            p = ProgressBar(dm_size)\n",
    "        \n",
    "            for i in range(0, x_s[0]):\n",
    "                for j in range(0, y_s[0]):\n",
    "                    dm[i, j] = self._dtw_distance(x[i, ::self.subsample_step],\n",
    "                                                  y[j, ::self.subsample_step])\n",
    "                    # Update progress bar\n",
    "                    dm_count += 1\n",
    "                    p.animate(dm_count)\n",
    "        \n",
    "            return dm\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\"Predict the class labels or probability estimates for \n",
    "        the provided data\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "          x : array of shape [n_samples, n_timepoints]\n",
    "              Array containing the testing data set to be classified\n",
    "          \n",
    "        Returns\n",
    "        -------\n",
    "          2 arrays representing:\n",
    "              (1) the predicted class labels \n",
    "              (2) the knn label count probability\n",
    "        \"\"\"\n",
    "        \n",
    "        dm = self._dist_matrix(x, self.x)\n",
    "\n",
    "        # Identify the k nearest neighbors\n",
    "        knn_idx = dm.argsort()[:, :self.n_neighbors]\n",
    "\n",
    "        # Identify k nearest labels\n",
    "        knn_labels = self.l[knn_idx]\n",
    "        \n",
    "        # Model Label\n",
    "        mode_data = mode(knn_labels, axis=1)\n",
    "        mode_label = mode_data[0]\n",
    "        mode_proba = mode_data[1]/self.n_neighbors\n",
    "\n",
    "        return mode_label.ravel(), mode_proba.ravel()\n",
    "\n",
    "class ProgressBar:\n",
    "    \"\"\"This progress bar was taken from PYMC\n",
    "    \"\"\"\n",
    "    def __init__(self, iterations):\n",
    "        self.iterations = iterations\n",
    "        self.prog_bar = '[]'\n",
    "        self.fill_char = '*'\n",
    "        self.width = 40\n",
    "        self.__update_amount(0)\n",
    "        if have_ipython:\n",
    "            self.animate = self.animate_ipython\n",
    "        else:\n",
    "            self.animate = self.animate_noipython\n",
    "\n",
    "    def animate_ipython(self, iter):\n",
    "        print('\\r', self,\n",
    "        sys.stdout.flush())\n",
    "        self.update_iteration(iter + 1)\n",
    "\n",
    "    def update_iteration(self, elapsed_iter):\n",
    "        self.__update_amount((elapsed_iter / float(self.iterations)) * 100.0)\n",
    "        self.prog_bar += '  %d of %s complete' % (elapsed_iter, self.iterations)\n",
    "\n",
    "    def __update_amount(self, new_amount):\n",
    "        percent_done = int(round((new_amount / 100.0) * 100.0))\n",
    "        all_full = self.width - 2\n",
    "        num_hashes = int(round((percent_done / 100.0) * all_full))\n",
    "        self.prog_bar = '[' + self.fill_char * num_hashes + ' ' * (all_full - num_hashes) + ']'\n",
    "        pct_place = (len(self.prog_bar) // 2) - len(str(percent_done))\n",
    "        pct_string = '%d%%' % percent_done\n",
    "        self.prog_bar = self.prog_bar[0:pct_place] + \\\n",
    "            (pct_string + self.prog_bar[pct_place + len(pct_string):])\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.prog_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = KnnDtw(n_neighbors=1, max_warping_window=2)\n",
    "#m2 = KnnDtw(n_neighbors=3, max_warping_window=2)\n",
    "#m3 = KnnDtw(n_neighbors=5, max_warping_window=2)\n",
    "\n",
    "m.fit(np.array(x_train_val), np.array(y_train_val))\n",
    "#m2.fit(np.array(x_train_val), np.array(y_train_val))\n",
    "#m3.fit(np.array(x_train_val), np.array(y_train_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0:'normal', 1:'abnormal'}\n",
    "label_1, proba_1 = m.predict(np.array(x_test))\n",
    "#label_2, proba_2 = m2.predict(np.array(x_test))\n",
    "#label_3, proba_3 = m3.predict(np.array(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17  1]\n",
      " [ 1 14]]\n",
      "acc: 0.9393939393939394\n",
      "0.9333333333333333\n",
      "0.9333333333333333\n",
      "f1: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "#print(classification_report(y_test, label, target_names=[l for l in labels.values()]))\n",
    "print(confusion_matrix(y_test, label_1))\n",
    "print('acc:', np.mean(y_test == label_1))\n",
    "print(precision_score(y_test, label_1, pos_label=1))\n",
    "print(recall_score(y_test, label_1, pos_label=1))\n",
    "print('f1:', f1_score(y_test, label_1, pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 0.8, 1. ,\n",
       "       1. , 1. , 1. , 1. , 1. , 0.8, 0.8, 1. , 1. , 1. , 1. , 1. , 1. ,\n",
       "       1. , 1. , 1. , 1. , 1. , 1. , 1. ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 0.66666667, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation\n",
    "raw_data = pd.read_csv('final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, raw_data.shape[0]):\n",
    "    raw_data.iloc[i,:-1] = (raw_data.iloc[i,:-1] - min(raw_data.iloc[i,:-1])) / (max(raw_data.iloc[i,:-1]) - min(raw_data.iloc[i,:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(raw_data.iloc[:,:-1])\n",
    "Y = raw_data.iloc[:,501]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = m2\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_acc = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []\n",
    "\n",
    "for train, test in kfold.split(X, Y):\n",
    "\n",
    "    # evaluate the model\n",
    "    best_model.fit(np.array(X[train]), np.array(Y[train]))\n",
    "    label, proba = best_model.predict(X[test])\n",
    "    \n",
    "    accuracy = np.mean(label == Y[test].values)\n",
    "    precision = precision_score(Y[test].values, label, pos_label=1)\n",
    "    recall = recall_score(Y[test].values, label, pos_label=1)\n",
    "    f_score = f1_score(Y[test].values, label, pos_label=1)\n",
    "    \n",
    "    cv_acc.append(accuracy)\n",
    "    cv_precision.append(precision)\n",
    "    cv_recall.append(recall)\n",
    "    cv_f1.append(f_score)\n",
    "    \n",
    "print('accuracy:', np.mean(cv_acc))\n",
    "print('precision:', np.mean(cv_precision))\n",
    "print('recall:', np.mean(cv_recall))\n",
    "print('f1:', np.mean(cv_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7142857142857143,\n",
       " 0.8333333333333334,\n",
       " 0.9090909090909091,\n",
       " 0.7692307692307693,\n",
       " 0.9090909090909091]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/envs/env_py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "lstm_model = load_model('LSTM_Final_Model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_arr = np.array(x_test)\n",
    "y_pred = lstm_model.predict_classes(x_test_arr.reshape(x_test_arr.shape[0],x_test_arr.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     normal       1.00      1.00      1.00        18\n",
      "   abnormal       1.00      1.00      1.00        15\n",
      "\n",
      "avg / total       1.00      1.00      1.00        33\n",
      "\n",
      "[[18  0]\n",
      " [ 0 15]]\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=[l for l in labels.values()]))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(np.mean(y_test==y_pred.flatten()))\n",
    "print(f1_score(y_test, y_pred, pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (base)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
